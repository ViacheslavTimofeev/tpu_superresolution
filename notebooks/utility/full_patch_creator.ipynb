{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03eff6e3-b240-4768-825b-6cb3689e7aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import math\n",
    "from typing import Tuple\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f6f5fdb-cb19-47f1-85ff-a47cfcb57c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Путь к исходному DeepRockSR-2D (как у тебя сейчас в train.py)\n",
    "DATA_ROOT = Path(\"../../DeepRockSR-2D\")  # подставь свой путь\n",
    "\n",
    "# Путь, куда складывать патчи\n",
    "OUT_ROOT = Path(\"../../DeepRockSR-2D_patches\")\n",
    "\n",
    "# Размер HR-патча\n",
    "PATCH_SIZE = 100  # например, 100x100\n",
    "\n",
    "# Масштаб суперразрешения (X2 или X4 и т.п.)\n",
    "UPSCALE = 4  # или 2, в зависимости от твоего эксперимента\n",
    "\n",
    "# Сплиты: исходное имя в DeepRock -> желаемый суффикс в папках патчей\n",
    "SPLITS = [\n",
    "    (\"train\", \"train\"),  # shuffled2D_train_HR -> HR_train/LR_train\n",
    "    (\"valid\", \"val\"),    # shuffled2D_valid_HR -> HR_val/LR_val\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d38e95d4-7a6c-48c0-8377-b97250b786a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_to_multiple_np(img: np.ndarray, patch_size: int) -> Tuple[np.ndarray, Tuple[int,int,int,int]]:\n",
    "    \"\"\"\n",
    "    img: np.ndarray (H, W) или (H, W, C)\n",
    "    Возвращает:\n",
    "      img_padded: np.ndarray\n",
    "      pads: (pad_left, pad_right, pad_top, pad_bottom)\n",
    "    \"\"\"\n",
    "    if img.ndim == 2:\n",
    "        h, w = img.shape\n",
    "        channels = None\n",
    "    elif img.ndim == 3:\n",
    "        h, w, channels = img.shape\n",
    "    else:\n",
    "        raise ValueError(f\"unexpected img ndim={img.ndim}, shape={img.shape}\")\n",
    "\n",
    "    n_h = math.ceil(h / patch_size)\n",
    "    n_w = math.ceil(w / patch_size)\n",
    "    H_pad = n_h * patch_size\n",
    "    W_pad = n_w * patch_size\n",
    "\n",
    "    pad_h = H_pad - h\n",
    "    pad_w = W_pad - w\n",
    "\n",
    "    pad_top = pad_h // 2\n",
    "    pad_bottom = pad_h - pad_top\n",
    "    pad_left = pad_w // 2\n",
    "    pad_right = pad_w - pad_left\n",
    "\n",
    "    if img.ndim == 2:\n",
    "        pads = ((pad_top, pad_bottom), (pad_left, pad_right))\n",
    "    else:\n",
    "        pads = ((pad_top, pad_bottom), (pad_left, pad_right), (0, 0))\n",
    "\n",
    "    img_padded = np.pad(img, pads, mode=\"reflect\")\n",
    "    return img_padded, (pad_left, pad_right, pad_top, pad_bottom)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "202c8ab0-34f9-4846-89bd-ce8d9d0f8dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_patches_from_hr_image(\n",
    "    hr_path: Path,\n",
    "    patch_size: int,\n",
    "    upscale: int,\n",
    ") -> Tuple[list[Image.Image], list[Image.Image]]:\n",
    "    \"\"\"\n",
    "    Читает один HR-файл, добавляет паддинг до кратности patch_size,\n",
    "    режет на патчи и для каждого HR-патча строит LR-патч через bicubic downscale.\n",
    "\n",
    "    Возвращает:\n",
    "      hr_patches: список PIL.Image (patch_size x patch_size)\n",
    "      lr_patches: список PIL.Image (patch_size//upscale x patch_size//upscale)\n",
    "    \"\"\"\n",
    "    # Читаем как grayscale (если хочешь, можешь сделать \"RGB\")\n",
    "    hr_img = Image.open(hr_path).convert(\"L\")\n",
    "    hr_np = np.array(hr_img).astype(np.float32)  # (H,W)\n",
    "\n",
    "    hr_np_padded, pads = pad_to_multiple_np(hr_np, patch_size)\n",
    "    H_pad, W_pad = hr_np_padded.shape\n",
    "\n",
    "    n_h = H_pad // patch_size\n",
    "    n_w = W_pad // patch_size\n",
    "\n",
    "    hr_patches = []\n",
    "    lr_patches = []\n",
    "\n",
    "    for i in range(n_h):\n",
    "        for j in range(n_w):\n",
    "            y0 = i * patch_size\n",
    "            x0 = j * patch_size\n",
    "            y1 = y0 + patch_size\n",
    "            x1 = x0 + patch_size\n",
    "\n",
    "            patch_np = hr_np_padded[y0:y1, x0:x1]  # (patch_size, patch_size)\n",
    "            patch_hr = Image.fromarray(patch_np.astype(np.float32), mode=\"F\")\n",
    "            # Если хочешь 8-bit для сохранения:\n",
    "            patch_hr_8 = patch_hr.convert(\"L\")\n",
    "\n",
    "            # Строим LR: downscale\n",
    "            lr_size = (patch_size // upscale, patch_size // upscale)\n",
    "            patch_lr = patch_hr_8.resize(lr_size, resample=Image.BICUBIC)\n",
    "\n",
    "            hr_patches.append(patch_hr_8)\n",
    "            lr_patches.append(patch_lr)\n",
    "\n",
    "    return hr_patches, lr_patches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1952f193-4ac0-49c7-ae86-cb2801f3b9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_split(\n",
    "    data_root: Path,\n",
    "    out_root: Path,\n",
    "    split_src: str,   # \"train\" или \"valid\" (как в DeepRock)\n",
    "    split_out: str,   # \"train\" или \"val\" (для имён папок HR_*/LR_*)\n",
    "    patch_size: int,\n",
    "    upscale: int,\n",
    "):\n",
    "    # Исходная директория HR (как в _get_dirs_deeprock)\n",
    "    hr_dir = data_root / \"shuffled2D\" / f\"shuffled2D_{split_src}_HR\"\n",
    "    if not hr_dir.is_dir():\n",
    "        raise FileNotFoundError(f\"HR dir not found: {hr_dir}\")\n",
    "\n",
    "    # Куда писаем патчи\n",
    "    out_hr_dir = out_root / f\"HR_{split_out}\"\n",
    "    out_lr_dir = out_root / f\"LR_{split_out}\"\n",
    "    out_hr_dir.mkdir(parents=True, exist_ok=True)\n",
    "    out_lr_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    hr_files = sorted([p for p in hr_dir.iterdir() if p.is_file() and p.suffix.lower() in (\".png\", \".tif\", \".tiff\", \".jpg\", \".jpeg\")])\n",
    "    print(f\"[{split_src}] HR files: {len(hr_files)}\")\n",
    "\n",
    "    patch_counter = 0\n",
    "\n",
    "    for hr_path in tqdm(hr_files, desc=f\"Processing {split_src}\"):\n",
    "        hr_patches, lr_patches = extract_patches_from_hr_image(\n",
    "            hr_path,\n",
    "            patch_size=patch_size,\n",
    "            upscale=upscale,\n",
    "        )\n",
    "\n",
    "        stem = hr_path.stem  # основа имени файла\n",
    "        for idx, (hr_patch, lr_patch) in enumerate(zip(hr_patches, lr_patches)):\n",
    "            # можно кодировать индекс патча как rXX_cYY, но для простоты возьмём просто _pXXXX\n",
    "            patch_name = f\"{stem}_p{idx:04d}.png\"\n",
    "\n",
    "            hr_out_path = out_hr_dir / patch_name\n",
    "            lr_out_path = out_lr_dir / patch_name\n",
    "\n",
    "            hr_patch.save(hr_out_path)\n",
    "            lr_patch.save(lr_out_path)\n",
    "\n",
    "            patch_counter += 1\n",
    "\n",
    "    print(f\"[{split_src}] total patches saved: {patch_counter}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ff8b6f8-a856-4975-88db-395fed18e7cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[train] HR files: 9600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train:   0%|                                                                       | 0/9600 [00:00<?, ?it/s]C:\\Users\\Вячеслав\\AppData\\Local\\Temp\\ipykernel_3836\\3563862906.py:35: DeprecationWarning: 'mode' parameter is deprecated and will be removed in Pillow 13 (2026-10-15)\n",
      "  patch_hr = Image.fromarray(patch_np.astype(np.float32), mode=\"F\")\n",
      "Processing train: 100%|████████████████████████████████████████████████████████████| 9600/9600 [04:03<00:00, 39.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[train] total patches saved: 240000\n",
      "[valid] HR files: 1200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing valid: 100%|████████████████████████████████████████████████████████████| 1200/1200 [00:34<00:00, 34.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[valid] total patches saved: 30000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "OUT_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for split_src, split_out in SPLITS:\n",
    "    process_split(\n",
    "        data_root=DATA_ROOT,\n",
    "        out_root=OUT_ROOT,\n",
    "        split_src=split_src,\n",
    "        split_out=split_out,\n",
    "        patch_size=PATCH_SIZE,\n",
    "        upscale=UPSCALE,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7698db-7c13-427e-89fc-54722ff80d04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
