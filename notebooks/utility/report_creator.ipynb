{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5659296b-fc17-4b5d-9fc3-ee900e5a7a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --------------------\n",
    "# настройки\n",
    "# --------------------\n",
    "MODEL_PT = Path(\"C:/Users/Вячеслав/Documents/superresolution/models/best_x2_ms_resunet.pt\")\n",
    "IMG_PATH = Path('C:/Users/Вячеслав/Documents/superresolution/DeepRockSR-2D/carbonate2D/carbonate2D_test_LR_default_X2/3607x2.png')\n",
    "OUT_PATH = Path('C:/Users/Вячеслав/Documents/superresolution/sr.png')\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# если у тебя grayscale SR: C=1; если RGB: C=3\n",
    "FORCE_GRAYSCALE = True\n",
    "\n",
    "# нормализация: чаще всего для SR используют [0,1]\n",
    "# если при обучении делал mean/std — нужно повторить ТОЧНО так же.\n",
    "USE_MEAN_STD = False\n",
    "MEAN = (0.5,)   # пример для 1 канала\n",
    "STD  = (0.5,)\n",
    "\n",
    "# --------------------\n",
    "# util: PIL -> tensor  (1,C,H,W)\n",
    "# --------------------\n",
    "def pil_to_tensor(img: Image.Image) -> torch.Tensor:\n",
    "    if FORCE_GRAYSCALE:\n",
    "        img = img.convert(\"L\")  # 1 канал\n",
    "        arr = np.array(img, dtype=np.float32) / 255.0          # H,W\n",
    "        t = torch.from_numpy(arr)[None, None, :, :]            # 1,1,H,W\n",
    "        if USE_MEAN_STD:\n",
    "            t = (t - MEAN[0]) / STD[0]\n",
    "        return t\n",
    "    else:\n",
    "        img = img.convert(\"RGB\")\n",
    "        arr = np.array(img, dtype=np.float32) / 255.0          # H,W,3\n",
    "        t = torch.from_numpy(arr).permute(2,0,1)[None, :, :, :]# 1,3,H,W\n",
    "        if USE_MEAN_STD:\n",
    "            mean = torch.tensor(MEAN).view(1,3,1,1)\n",
    "            std  = torch.tensor(STD).view(1,3,1,1)\n",
    "            t = (t - mean) / std\n",
    "        return t\n",
    "\n",
    "# --------------------\n",
    "# util: tensor -> PIL\n",
    "# --------------------\n",
    "def tensor_to_pil(t: torch.Tensor) -> Image.Image:\n",
    "    # ожидаем 1,C,H,W или C,H,W\n",
    "    if t.ndim == 4:\n",
    "        t = t[0]\n",
    "    t = t.detach().float().cpu()\n",
    "\n",
    "    if USE_MEAN_STD:\n",
    "        if t.shape[0] == 1:\n",
    "            t = t * STD[0] + MEAN[0]\n",
    "        else:\n",
    "            mean = torch.tensor(MEAN).view(3,1,1)\n",
    "            std  = torch.tensor(STD).view(3,1,1)\n",
    "            t = t * std + mean\n",
    "\n",
    "    t = t.clamp(0, 1)\n",
    "\n",
    "    if t.shape[0] == 1:\n",
    "        arr = (t[0].numpy() * 255.0).round().astype(np.uint8)  # H,W\n",
    "        return Image.fromarray(arr, mode=\"L\")\n",
    "    else:\n",
    "        arr = (t.permute(1,2,0).numpy() * 255.0).round().astype(np.uint8)  # H,W,3\n",
    "        return Image.fromarray(arr, mode=\"RGB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "801c558a-20e9-4312-9975-2b4e8dca1234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Вячеслав\\Documents\\superresolution\\modules\n"
     ]
    }
   ],
   "source": [
    "%cd C:\\Users\\Вячеслав\\Documents\\superresolution\\modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4884615c-a2b3-47e6-af60-7fdbe99b1813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cwd: C:\\Users\\Вячеслав\\Documents\\superresolution\\modules\n",
      "python: C:\\anaconda\\envs\\superresolution\\python.exe\n",
      "first sys.path entries: ['C:\\\\anaconda\\\\envs\\\\superresolution\\\\python313.zip', 'C:\\\\anaconda\\\\envs\\\\superresolution\\\\DLLs', 'C:\\\\anaconda\\\\envs\\\\superresolution\\\\Lib', 'C:\\\\anaconda\\\\envs\\\\superresolution', '']\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "print(\"cwd:\", os.getcwd())\n",
    "print(\"python:\", sys.executable)\n",
    "print(\"first sys.path entries:\", sys.path[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "91248647-7f70-46f3-8af1-677c83794dd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: C:\\Users\\Вячеслав\\Documents\\superresolution\\models\\best_x2_ms_resunet.pt\n",
      "Missing: 0\n",
      "Unexpected: 0\n",
      "Missing examples: []\n",
      "Unexpected examples: []\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from collections import OrderedDict\n",
    "\n",
    "# 1) Импорт архитектуры (ВАЖНО: поправь импорт под свой файл)\n",
    "# Ты писал, что архитектура у тебя в стиле:\n",
    "# def MS_ResUNet():\n",
    "#     model = RefineNet(Bottleneck, [3, 4, 3, 3])\n",
    "#     return model\n",
    "#\n",
    "# Значит нужно импортировать RefineNet и Bottleneck оттуда, где они реально лежат.\n",
    "# Примеры (выбери один правильный для твоего проекта):\n",
    "# from refinenet import RefineNet, Bottleneck\n",
    "# from model import RefineNet, Bottleneck\n",
    "# from networks.refinenet import RefineNet, Bottleneck\n",
    "\n",
    "from ms_resunet import RefineNet, Bottleneck  # <-- ПОДСТАВЬ СВОЙ ПРАВИЛЬНЫЙ ПУТЬ\n",
    "\n",
    "def MS_ResUNet():\n",
    "    return RefineNet(Bottleneck, [3, 4, 3, 3])\n",
    "\n",
    "def _extract_state_dict(ckpt):\n",
    "    \"\"\"Достаёт state_dict из разных форматов чекпоинта.\"\"\"\n",
    "    if isinstance(ckpt, torch.nn.Module):\n",
    "        # torch.save(model)\n",
    "        return ckpt.state_dict()\n",
    "\n",
    "    if not isinstance(ckpt, dict):\n",
    "        # редкий кейс: сохранён просто OrderedDict без dict-обёртки\n",
    "        if isinstance(ckpt, (OrderedDict, dict)):\n",
    "            return ckpt\n",
    "        raise TypeError(f\"Неожиданный тип чекпоинта: {type(ckpt)}\")\n",
    "\n",
    "    # самые частые варианты:\n",
    "    for key in [\"model\", \"state_dict\", \"model_state_dict\", \"net\", \"generator\", \"g\"]:\n",
    "        if key in ckpt and isinstance(ckpt[key], (dict, OrderedDict)):\n",
    "            return ckpt[key]\n",
    "\n",
    "    # иногда сам dict и есть state_dict (ключи вида 'layer.weight')\n",
    "    if any(isinstance(k, str) and k.endswith((\".weight\", \".bias\")) for k in ckpt.keys()):\n",
    "        return ckpt\n",
    "\n",
    "    # покажем ключи, чтобы быстро понять формат\n",
    "    raise KeyError(f\"Не нашёл state_dict в чекпоинте. Ключи верхнего уровня: {list(ckpt.keys())[:50]}\")\n",
    "\n",
    "def _strip_prefix(state, prefix=\"module.\"):\n",
    "    \"\"\"Убирает 'module.' после DDP/DataParallel.\"\"\"\n",
    "    if not any(k.startswith(prefix) for k in state.keys()):\n",
    "        return state\n",
    "    out = OrderedDict()\n",
    "    for k, v in state.items():\n",
    "        out[k[len(prefix):] if k.startswith(prefix) else k] = v\n",
    "    return out\n",
    "\n",
    "# 2) Создаём модель\n",
    "model = MS_ResUNet()\n",
    "\n",
    "# 3) Грузим чекпоинт\n",
    "ckpt = torch.load(MODEL_PT, map_location=\"cpu\")\n",
    "state = _extract_state_dict(ckpt)\n",
    "state = _strip_prefix(state, \"module.\")\n",
    "\n",
    "# 4) Загружаем веса\n",
    "missing, unexpected = model.load_state_dict(state, strict=True)\n",
    "\n",
    "print(\"Loaded:\", MODEL_PT)\n",
    "print(\"Missing:\", len(missing))\n",
    "print(\"Unexpected:\", len(unexpected))\n",
    "print(\"Missing examples:\", missing[:20])\n",
    "print(\"Unexpected examples:\", unexpected[:20])\n",
    "\n",
    "# 5) На устройство и в eval\n",
    "model = model.to(DEVICE).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d6fb3512-5012-4e9c-a814-54655c26fa01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: C:\\Users\\Вячеслав\\Documents\\superresolution\\sr.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Вячеслав\\AppData\\Local\\Temp\\ipykernel_26232\\2155808775.py:67: DeprecationWarning: 'mode' parameter is deprecated and will be removed in Pillow 13 (2026-10-15)\n",
      "  return Image.fromarray(arr, mode=\"L\")\n"
     ]
    }
   ],
   "source": [
    "img = Image.open(IMG_PATH)\n",
    "x = pil_to_tensor(img).to(DEVICE)\n",
    "\n",
    "with torch.no_grad():\n",
    "    y = model(x)\n",
    "\n",
    "# иногда модель возвращает tuple/list (например, (sr, aux))\n",
    "if isinstance(y, (tuple, list)):\n",
    "    y = y[0]\n",
    "\n",
    "out_img = tensor_to_pil(y)\n",
    "out_img.save(OUT_PATH)\n",
    "\n",
    "print(\"Saved:\", OUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e91d12ba-9720-411c-b7dc-2c48f08577c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x device: cuda:0\n",
      "model device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "print(\"x device:\", x.device)\n",
    "print(\"model device:\", next(model.parameters()).device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4f866c3a-957c-46cf-8b44-43ad682b54fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: C:\\Users\\Вячеслав\\Documents\\superresolution\\sr.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Вячеслав\\AppData\\Local\\Temp\\ipykernel_26232\\2497787645.py:33: DeprecationWarning: 'mode' parameter is deprecated and will be removed in Pillow 13 (2026-10-15)\n",
      "  Image.fromarray(img_out, mode=\"L\").save(OUT_PATH)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "from torchvision.transforms import v2 as T\n",
    "from torchvision.transforms.v2 import functional as TF\n",
    "from torchvision.transforms.v2.functional import InterpolationMode\n",
    "\n",
    "DEVICE   = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "LR_PATH  = Path('C:/Users/Вячеслав/Documents/superresolution/DeepRockSR-2D/carbonate2D/carbonate2D_test_LR_default_X2/3607x2.png')\n",
    "HR_PATH  = Path('C:/Users/Вячеслав/Documents/superresolution/DeepRockSR-2D/carbonate2D/carbonate2D_test_HR/3607.png')\n",
    "OUT_PATH = Path('C:/Users/Вячеслав/Documents/superresolution/sr.png')\n",
    "\n",
    "# --- те же преобразования, что в val ---\n",
    "to_img = T.ToImage()\n",
    "to_f32 = T.ToDtype(torch.float32, scale=True)\n",
    "\n",
    "lr = Image.open(LR_PATH).convert(\"L\")\n",
    "hr = Image.open(HR_PATH).convert(\"L\")\n",
    "\n",
    "if lr.size != hr.size:  # PIL size=(W,H)\n",
    "    lr = TF.resize(lr, size=[hr.size[1], hr.size[0]], interpolation=InterpolationMode.BICUBIC, antialias=True)\n",
    "\n",
    "x = to_f32(to_img(lr)).unsqueeze(0).to(DEVICE)   # (1,1,H,W) float32 в [0,1]\n",
    "\n",
    "model = model.to(DEVICE).eval()\n",
    "with torch.no_grad():\n",
    "    y = model(x)\n",
    "if isinstance(y, (tuple, list)):\n",
    "    y = y[0]\n",
    "\n",
    "# сохранить (ожидается, что y тоже в [0,1])\n",
    "img_out = (y[0,0].detach().clamp(0,1).cpu().numpy() * 255).round().astype(\"uint8\")\n",
    "Image.fromarray(img_out, mode=\"L\").save(OUT_PATH)\n",
    "print(\"Saved:\", OUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413f74a0-8f20-4f9c-94c2-eea292db1d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "# ===================== НАСТРОЙКИ =====================\n",
    "FOLDER = Path(\"C:/Users/Вячеслав/Documents/superresolution/report\")\n",
    "BASE_ID = None          # например \"3607\" или None (тогда сделает отчёты по всем найденным id)\n",
    "OUT_DIR = FOLDER        # куда сохранять отчёты\n",
    "GRID = 4                # 4x4 = 16 патчей\n",
    "RECT_WIDTH = 4\n",
    "PAD = 12                # отступы между плитками\n",
    "TITLE_H = 100          # высота области под подписи в каждой ячейке\n",
    "# =====================================================\n",
    "\n",
    "from PIL import ImageFont\n",
    "from pathlib import Path\n",
    "\n",
    "def pick_font(size=90):\n",
    "    font_path = Path(r\"C:\\Windows\\Fonts\\arial.ttf\")\n",
    "    return ImageFont.truetype(str(font_path), size=size)\n",
    "\n",
    "FONT = pick_font(70)\n",
    "\n",
    "def find_triplets(folder: Path):\n",
    "    \"\"\"Ищем базовые id, у которых есть *_hr, *_lr, *_sr (с любым расширением).\"\"\"\n",
    "    hr = {p.stem[:-3]: p for p in folder.glob(\"*_hr.*\")}  # stem: 3607_hr -> base: 3607\n",
    "    lr = {p.stem[:-3]: p for p in folder.glob(\"*_lr.*\")}\n",
    "    sr = {p.stem[:-3]: p for p in folder.glob(\"*_sr.*\")}\n",
    "    bases = sorted(set(hr) & set(lr) & set(sr))\n",
    "    return [(b, hr[b], lr[b], sr[b]) for b in bases]\n",
    "\n",
    "def tile_with_title(img: Image.Image, title: str, cell_w: int, cell_h: int):\n",
    "    \"\"\"Картинка + подпись снизу (внутри одной ячейки).\"\"\"\n",
    "    canvas = Image.new(\"RGB\", (cell_w, cell_h + TITLE_H), (20, 20, 20))\n",
    "    # если img не RGB — конвертируем для вставки\n",
    "    if img.mode != \"RGB\":\n",
    "        img = img.convert(\"RGB\")\n",
    "    canvas.paste(img, (0, 0))\n",
    "\n",
    "    draw = ImageDraw.Draw(canvas)\n",
    "    draw.text((8, cell_h + 5), title, fill=(240, 240, 240), font=FONT)\n",
    "    return canvas\n",
    "\n",
    "def make_report_for_id(base: str, hr_path: Path, lr_path: Path, sr_path: Path, out_path: Path):\n",
    "    hr = Image.open(hr_path)\n",
    "    lr = Image.open(lr_path)\n",
    "    sr = Image.open(sr_path)\n",
    "\n",
    "    # Приводим к grayscale/или оставляем как есть — тут чаще всего grayscale.\n",
    "    # Если у тебя цвет, можешь убрать convert(\"L\").\n",
    "    hr = hr.convert(\"L\")\n",
    "    lr = lr.convert(\"L\")\n",
    "    sr = sr.convert(\"L\")\n",
    "\n",
    "    W, H = hr.size\n",
    "    assert W % GRID == 0 and H % GRID == 0, f\"HR размер {W}x{H} должен делиться на GRID={GRID}\"\n",
    "    pw, ph = W // GRID, H // GRID\n",
    "\n",
    "    # Чтобы патчи совпадали по координатам — LR/SR ресайзим под HR (если отличаются)\n",
    "    if lr.size != hr.size:\n",
    "        lr = lr.resize((W, H), resample=Image.BICUBIC)\n",
    "    if sr.size != hr.size:\n",
    "        sr = sr.resize((W, H), resample=Image.BICUBIC)\n",
    "\n",
    "    # Размер одной \"картинки\" в ячейке: показываем патчи в масштабе full-size HR\n",
    "    CELL_W, CELL_H = W, H\n",
    "\n",
    "    rows = GRID * GRID\n",
    "    cols = 4\n",
    "    out_w = PAD + cols * (CELL_W + PAD)\n",
    "    out_h = PAD + rows * (CELL_H + TITLE_H + PAD)\n",
    "\n",
    "    report = Image.new(\"RGB\", (out_w, out_h), (15, 15, 15))\n",
    "    draw_global = ImageDraw.Draw(report)\n",
    "\n",
    "    # Сдвиг вниз чуть-чуть, чтобы заголовок не лип к первому ряду\n",
    "    y0_base = PAD + 24\n",
    "\n",
    "    idx = 0\n",
    "    for r in range(GRID):\n",
    "        for c in range(GRID):\n",
    "            x0, y0 = c * pw, r * ph\n",
    "            x1, y1 = x0 + pw, y0 + ph\n",
    "\n",
    "            hr_patch = hr.crop((x0, y0, x1, y1)).resize((CELL_W, CELL_H), resample=Image.NEAREST)\n",
    "            lr_patch = lr.crop((x0, y0, x1, y1)).resize((CELL_W, CELL_H), resample=Image.NEAREST)\n",
    "            sr_patch = sr.crop((x0, y0, x1, y1)).resize((CELL_W, CELL_H), resample=Image.NEAREST)\n",
    "\n",
    "            # HR full с красной рамкой патча\n",
    "            hr_box = hr.convert(\"RGB\")\n",
    "            d = ImageDraw.Draw(hr_box)\n",
    "            d.rectangle([x0, y0, x1 - 1, y1 - 1], outline=(255, 0, 0), width=RECT_WIDTH)\n",
    "\n",
    "            # Подписи\n",
    "            t_hr = tile_with_title(hr_patch, f\"HR patch [{r},{c}]\", CELL_W, CELL_H)\n",
    "            t_lr = tile_with_title(lr_patch, f\"LR patch [{r},{c}]\", CELL_W, CELL_H)\n",
    "            t_sr = tile_with_title(sr_patch, f\"SR patch [{r},{c}]\", CELL_W, CELL_H)\n",
    "            t_full = tile_with_title(hr_box,   f\"HR full\", CELL_W, CELL_H)\n",
    "\n",
    "            # Позиции в отчёте\n",
    "            row_y = y0_base + idx * (CELL_H + TITLE_H + PAD)\n",
    "\n",
    "            def paste_col(col_i, tile):\n",
    "                x = PAD + col_i * (CELL_W + PAD)\n",
    "                report.paste(tile, (x, row_y))\n",
    "\n",
    "            paste_col(0, t_hr)\n",
    "            paste_col(1, t_lr)\n",
    "            paste_col(2, t_sr)\n",
    "            paste_col(3, t_full)\n",
    "\n",
    "            idx += 1\n",
    "\n",
    "    out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    if out_path.suffix == \"\":\n",
    "        out_path = out_path.with_suffix(\".png\")\n",
    "    report.save(out_path)\n",
    "    return out_path\n",
    "\n",
    "# ---------- ЗАПУСК ----------\n",
    "triplets = find_triplets(FOLDER)\n",
    "if not triplets:\n",
    "    raise FileNotFoundError(\"Не нашёл в папке тройки *_hr.*, *_lr.*, *_sr.*\")\n",
    "\n",
    "targets = triplets\n",
    "if BASE_ID is not None:\n",
    "    targets = [t for t in triplets if t[0] == BASE_ID]\n",
    "    if not targets:\n",
    "        raise FileNotFoundError(f\"Не нашёл тройку для BASE_ID={BASE_ID}\")\n",
    "\n",
    "saved_paths = []\n",
    "for base, hr_p, lr_p, sr_p in targets:\n",
    "    out = OUT_DIR / f\"{base}_patch_report.png\"\n",
    "    saved = make_report_for_id(base, hr_p, lr_p, sr_p, out)\n",
    "    saved_paths.append(saved)\n",
    "    print(\"Saved:\", saved)\n",
    "\n",
    "saved_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5704ae87-7de6-45f3-b7c6-0fa03e2ba38d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
