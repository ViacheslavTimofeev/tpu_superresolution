{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22fe38ea-2aed-414a-9cdc-b23f7c8fb935",
   "metadata": {},
   "source": [
    "# Планы на будущее"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6aa7cc7-1795-4539-8d1c-a87e9a450e70",
   "metadata": {},
   "source": [
    "## Данные"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff6608d-ad8c-4a0c-8ef5-bdb82468a374",
   "metadata": {},
   "source": [
    "1. Рассматривается возможность использовать данные срезов одного керна вместо множества случайных;\n",
    "2. Более высокое разрешение изначальных изображений (условные 1024x1024 вместо 500x500);\n",
    "3. (В идеале) Настоящие данные заказчика;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf18355e-6578-4286-a4ed-4722e3a8ac3a",
   "metadata": {},
   "source": [
    "## Предобработка\n",
    "1. Исследования влияния `GaussianBlur` на качество;\n",
    "2. Добавление новых аугментаций и преобразований;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01d6ef8-1b4b-4327-82a8-ff292be15c3c",
   "metadata": {},
   "source": [
    "## Модели"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5f1c61-b874-461d-a237-96cd39000e71",
   "metadata": {},
   "source": [
    "1. Создать Diffusion Model:\n",
    "   * DDNM\n",
    "2. Создать GAN (в приоретете):\n",
    "   * ESRGAN (в приоретете)\n",
    "   * CycleGAN\n",
    "3. Найти и создать более продвинутую CNN, чем U-Net;\n",
    "4. Эксперименты с параметрами U-Net;\n",
    "5. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f983ef42-bc27-453a-826c-17311006eef4",
   "metadata": {},
   "source": [
    "## Процесс обучения"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534e8b24-c949-4bfe-afd3-8ef44c549ef9",
   "metadata": {},
   "source": [
    "1. Добавить `scheduler`;\n",
    "2. Эксперименты с разными `optimizer`;\n",
    "3. Исследования влияния `BatchNorm` на качество:\n",
    "4. Исследования в использовании `L1`, `MSE`, `L1 + (1 - SSIM)` как функций потерь; "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db08f1f1-5144-4a25-b3d2-239ca8e91225",
   "metadata": {},
   "source": [
    "## Код"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6213c01-fc88-4ba7-aa10-ce1782337c71",
   "metadata": {},
   "source": [
    "1. Сделать код более переиспользуемым:\n",
    "   * вынести этапы предобработки (и, возможно, загрузчики) в отдельный модуль;\n",
    "2. Сделать предобработку общей для всех моделей, где это возможно;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b0e95f9-0c60-46a2-b6be-81582ac688ee",
   "metadata": {},
   "source": [
    "## Логирование"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fac8c80-f556-4c5b-98a2-a415d04a5bf7",
   "metadata": {},
   "source": [
    "1. Добавить поддержку W&B или MLflow;\n",
    "2. Создать GitHub-репозиторий."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e7ccaa-8a66-465e-bda9-8cbd2f5501ea",
   "metadata": {},
   "source": [
    "### Что делать в первую очередь (высокий приоритет)\n",
    "\n",
    "Диапазоны, метрики и протокол\n",
    "\n",
    "Тренируй и валидируй в [0,1].\n",
    "\n",
    "Для PSNR/SSIM делай shave = scale (обрезай по краям) — иначе апсемплинговые границы портят метрику.\n",
    "\n",
    "Стабильный SSIM: fp32, kernel_size=7 (или 5 на мелких патчах), gaussian_weights=True, eps > 0.\n",
    "\n",
    "Если используешь Normalize(mean,std) для входа — для метрик обратно денормализуй.\n",
    "\n",
    "Патчи и аугментации (дают больше, чем выбор лосса)\n",
    "\n",
    "Подбери patch_size: для x2 попробуй 128→192→256. Б óльший патч = больше контекста → обычно ↑SSIM/PSNR.\n",
    "\n",
    "Аугментации умеренные: flips/rot90, лёгкий GaussianNoise. Откажись от сильного blur — он конфликтует с задачей SR (LR уже деградированы).\n",
    "\n",
    "Следи, чтобы HR/LR кропы были строго согласованы по координатам.\n",
    "\n",
    "Нормализации в U-Net\n",
    "\n",
    "Убрать BatchNorm — хорошая идея для маленьких батчей. Альтернатива: GroupNorm(32) или InstanceNorm — часто стабильнее.\n",
    "\n",
    "Если BN оставляешь, валидируй с model.eval() и не смешивай разные масштабы в одном батче.\n",
    "\n",
    "Оптимизация и стабильность шага\n",
    "\n",
    "AdamW lr=2e-4, weight_decay=1e-4 (или Adam без WD, если лезут артефакты).\n",
    "\n",
    "CosineAnnealing с warmup 3–5 эпох или OneCycleLR — на SR обычно надёжно.\n",
    "\n",
    "Градиент-клиппинг: clip_grad_norm_(..., 1.0).\n",
    "\n",
    "EMA весов (decay ~0.999) часто даёт +0.05–0.15 dB PSNR.\n",
    "\n",
    "Лосс — стабильная база\n",
    "\n",
    "Вместо L1 + (1-SSIM) попробуй: Charbonnier (√(x²+ε²)) + MS-SSIM.\n",
    "Рецепт: 0.84 * Charbonnier + 0.16 * (1 - MS-SSIM); MS-SSIM считать в fp32, затем смешивать.\n",
    "\n",
    "Если остаёшься на L1+SSIM: считай SSIM в fp32 и клампи ssim.clamp(0,1).\n",
    "\n",
    "### Дальше по важности (средний приоритет)\n",
    "\n",
    "Глубина/ширина U-Net\n",
    "\n",
    "Сделай глубину 4–5 даунсемплов, базовые каналы 64 (или 48, если память).\n",
    "\n",
    "В декодере избегай “шахматки”: upsample (nearest/bilinear) + conv вместо ConvTranspose2d. Это уменьшит артефакты и даст +к стабильности.\n",
    "\n",
    "Резидуализация блока\n",
    "\n",
    "Перейди на Res-UNet (residual conv-блоки внутри энкодера/декодера). Часто даёт заметный прирост при той же сложности.\n",
    "\n",
    "Внимание (легковесно)\n",
    "\n",
    "SE/SCSE/CBAM в скип-конкатенациях или в бутылочном блоке. Дёшево и иногда ощутимо ↑SSIM на текстурах.\n",
    "\n",
    "Куррикулум по масштабам\n",
    "\n",
    "Обучи x2 до сходимости → инициализируй x4 этими весами → финтюн с lr в 3–5 раз меньше. Обычно лучше, чем “параллельно”.\n",
    "\n",
    "Валид. протокол и сиды\n",
    "\n",
    "Фиксируй сиды, список валид-патчей/картинок, единый shave, единые пред-/пост-процедуры. Иначе шум в +0.01 SSIM легко “съест” эффект.\n",
    "\n",
    "### Низкий приоритет / точечные усилители\n",
    "\n",
    "Перцептуальный лосс\n",
    "\n",
    "VGG-перцептуальный (relu2_2/relu3_3) с маленьким весом (например 0.01–0.05) — иногда улучшает визуально, но часто снижает PSNR. Пробуй, если важна визуалка.\n",
    "\n",
    "TTA / self-ensemble на тесте\n",
    "\n",
    "x8-self-ensemble (flip/rot) даёт +0.05–0.2 dB без ретрейна.\n",
    "\n",
    "Регуляризация\n",
    "\n",
    "TV-регуляризатор на предсказании с маленьким весом может убирать “дрожь” на гранях. Аккуратно, чтобы не замылить.\n",
    "\n",
    "Базовый “эталон” конфиг, от которого плясать\n",
    "\n",
    "Data: patch=192 (x2), flips+rot90, лёгкий noise; batch_size=8; workers=8.\n",
    "\n",
    "Model: UNet(depth=5, base_ch=64), без BN (или GroupNorm), upsample+conv, LeakyReLU.\n",
    "\n",
    "Loss: 0.84 * Charbonnier(eps=1e-3) + 0.16 * (1 - MS-SSIM); MS-SSIM в fp32.\n",
    "\n",
    "Optim: AdamW(lr=2e-4, wd=1e-4), cosine + 5 эпох warmup, grad-clip=1.0, EMA=0.999.\n",
    "\n",
    "Training: AMP включён, кроме SSIM; epochs_x2=150 с ранней остановкой (patience=20, min_delta=0.002 SSIM).\n",
    "\n",
    "Validation: model.eval(), no_grad, денормализация перед метриками, PSNR/SSIM со shave=scale.\n",
    "\n",
    "Logging: логи лосса по компонентам (L1/Charbonnier и (1-SSIM)) и финального суммарного; следи за их соотношением.\n",
    "\n",
    "Что проверить в твоих текущих запусках (быстрые выигрыши)\n",
    "\n",
    "Убедись, что SSIM считается в fp32 и с корректным data_range.\n",
    "\n",
    "Попробуй patch_size=192/256 — часто даёт больший прирост, чем замена лосса.\n",
    "\n",
    "Оставь вариант без нормализаций (или с GroupNorm) — на маленьком батче это часто лучший сетап.\n",
    "\n",
    "Включи EMA и grad-clip — добавляет стабильности и пару сотых SSIM “на халяву”.\n",
    "\n",
    "Проверь shave при валидации — без него сравнение разных конфигов шумное."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b40849f-a2d9-4a0d-8740-6acc43cbdba0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
